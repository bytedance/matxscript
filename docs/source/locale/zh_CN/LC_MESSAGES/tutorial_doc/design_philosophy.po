# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, Bytedance Inc.
# This file is distributed under the same license as the Matxscript package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Matxscript \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-12-10 03:03+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../source/tutorial_doc/design_philosophy.rst:4
msgid "Design Philosophy"
msgstr "设计哲学"

#: ../../source/tutorial_doc/design_philosophy.rst:7
msgid "Overview"
msgstr "总览"

#: ../../source/tutorial_doc/design_philosophy.rst:8
msgid ""
"Matx is originally designed to integrate training and inference in "
"machine learning production system. It comes with the following goals:"
msgstr "Matx 旨在将机器学习生产系统中的训练和推理一体化，具体目标为："

#: ../../source/tutorial_doc/design_philosophy.rst:10
msgid "Python interpreter is not required during deployment."
msgstr "在部署模型时不需要Python编译器。"

#: ../../source/tutorial_doc/design_philosophy.rst:11
msgid ""
"Existing Python code that performs data preprocessing and postprocessing "
"need not to be rewritten."
msgstr "已有的前后处理代码可直接使用在推理中。"

#: ../../source/tutorial_doc/design_philosophy.rst:12
msgid "The generated code should run faster than the original Python version."
msgstr "自动生成比Python 代码更快的代码。"

#: ../../source/tutorial_doc/design_philosophy.rst:14
msgid ""
"Given them, Matx is an ahead-of-time compiler that transforms Python into"
" C++. Besides machine learning applications, we expect Matx to be used in"
" a wider range of applications that involve translating Python into C++ "
"for better performance."
msgstr "为实现这些目标，我们将 matx 设计为一个 Python 代码的超前编译器，将Python 代码自动编译成C++。目前 Matx 主要支持机器学习相关的应用，但我们预期将 matx 推广到更多对性能敏感的python应用。"

#: ../../source/tutorial_doc/design_philosophy.rst:17
msgid "High-level Concepts"
msgstr "顶层设计"

#: ../../source/tutorial_doc/design_philosophy.rst:20
msgid "Script"
msgstr "编译 (Script)"

#: ../../source/tutorial_doc/design_philosophy.rst:21
msgid ""
"Script is used to compile a Python function/class into a C++ "
"function/class with Python wrapper. The Python wrapper has identical "
"behavior as the original Python function/class."
msgstr "Script 可将 Python 函数/类编译为一个经过编译和包装并可在Python直接调用的的c++ 函数/类。"

#: ../../source/tutorial_doc/design_philosophy.rst:24
msgid "Operation (Op)"
msgstr "算子 (Op)"

#: ../../source/tutorial_doc/design_philosophy.rst:25
msgid ""
"An operation (Op) is a compiled C++ function or a method of the compiled "
"C++ class. It is the basic component used to construct a computational "
"graph via tracing."
msgstr "算子是编译后的C++函数或编译C++类的方法，是用于通过跟踪构建计算图的基本组件。"

#: ../../source/tutorial_doc/design_philosophy.rst:28
msgid "Trace"
msgstr "自动成图 (Trace)"

#: ../../source/tutorial_doc/design_philosophy.rst:29
msgid ""
"Trace is used to generate a computational graph composed of operations. "
"Note that the computational graph must be a directly asyclic graph. The "
"computational graph can be directly executed in Python. It can also be "
"saved/loaded to/from disk files."
msgstr "自动成图(Trace)用于自动生成由用户代码所组成的计算图。请注意，我们要求计算图必须是有向无循环图。生成的计算图在可以直接在Python中执行，也可以在保存后从磁盘文件加载。"

#: ../../source/tutorial_doc/design_philosophy.rst:32
msgid "Python First"
msgstr "Python 优先"

#: ../../source/tutorial_doc/design_philosophy.rst:33
msgid ""
"Matx is an ahead-of-time compiler that compiles Python into C++. We "
"choose Python as it is the dominate programming language in deep learning"
" and has a large existing codebase. Note that we only support a subset of"
" Python due to performance consideration."
msgstr "之所以我们选择 Python 是因为它是深度学习中的主要编程语言，并且拥有大量现有代码库。请注意，出于性能考虑，我们只支持 Python 语法的子集。"

#: ../../source/tutorial_doc/design_philosophy.rst:36
msgid "Fast Execution"
msgstr "快速执行"

#: ../../source/tutorial_doc/design_philosophy.rst:37
msgid ""
"As compiled code from Matx  is written in C++, it naturally achieves "
"orders of speedup compared with the original Python code executed by "
"Python Interpreter. To further improve the performance, we enforce type "
"annotation when writing Python code."
msgstr "由于在经过编译(script) 后，我们将用户的Python代码转换为了C++，所以在与使用 Python 解释器运行的代码相比，生成的c++代码为我们带来了几个数量级的性能提升。除此之外，我们还要求用户对其Python代码进行类型标注，这样可以进一步提升性能。"

#: ../../source/tutorial_doc/design_philosophy.rst:40
msgid "Extensions Without Pain"
msgstr "轻松扩展"

#: ../../source/tutorial_doc/design_philosophy.rst:41
msgid "Writing custom C++ Operations can be easily integrated into Matx."
msgstr "用户编写的C++/python 算子可以轻松集成到Matx中。"

#: ../../source/tutorial_doc/design_philosophy.rst:44
msgid "Machine Learning Support"
msgstr "机器学习支持"

#: ../../source/tutorial_doc/design_philosophy.rst:47
msgid "Preprocessing and Postprocessing"
msgstr "前后处理"

#: ../../source/tutorial_doc/design_philosophy.rst:48
msgid ""
"Data preprocessing and postprocessing are two key components in machine "
"learning production systems. In NLP, data preprocessing includes text "
"cleaning, text augmentation and tokenizing. A large portion of existing "
"codebase is written in Python. With Matx, Developers can integrate data "
"preprocessing code into neural network inference code easily."
msgstr ""

#: ../../source/tutorial_doc/design_philosophy.rst:51
msgid "Pytorch/TensorFlow Integration"
msgstr "数据的前后处理是机器学习生产系统中的两个关键组件。现有的大部分代码库是用Python编写的。使用Matx，开发人员可以轻松地将数据预处理代码集成到神经网络推理代码中。"

