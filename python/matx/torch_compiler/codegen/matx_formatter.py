# Copyright 2022 ByteDance Ltd. and/or its affiliates.
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

"""
Utilities to format kernel code generated by inductor to a JITOp
"""

import copy
import logging
from typing import List

import torch

from .utils import cpp_parse

log = logging.getLogger(__name__)

MAGIC_NUMBER = '2_71828182846'

MATX_INCLUDE = '''
#include "matxscript/runtime/codegen_all_includes.h"
#include <math.h>

using namespace ::matxscript::runtime;
extern "C" void* __matxscript_module_ctx = NULL;

extern "C" MATX_DLL MATXScriptFuncRegistry __matxscript_func_registry__;



'''

SESSION_HANLDER = cpp_parse.CPPArg(name=f'handle_{MAGIC_NUMBER}',
                                   type=cpp_parse.CPPType(name='void', is_pointer=True))
SESSION_HANLDER_WITH_DEAFULT = cpp_parse.CPPArg(
    name=f'handle_{MAGIC_NUMBER}', type=cpp_parse.CPPType(
        name='void', is_pointer=True), default_val='((void*)(int64_t)0)')

CREATE_NDARRAY_IMPLEMENTATION = '''
NDArray createNDArray(const std::string& dtype, const std::string& device, const List& arg_shape) {
  Unicode dtype_str(UTF8Decode(dtype));
  Unicode ctx_str(UTF8Decode(device));

  auto a = Kernel_NDArray::make(0., arg_shape, dtype_str, ctx_str);
  // set impl to torch.Tensor
  a.SetImpl(NDArray::Impl::torchTensor);
  return a;
}
'''


def generate_ndarray_arg_cast(arg_name, arg_index, message='TODO'):
    return f'internal::TypeAsHelper<NDArray>::run(({arg_name}[{arg_index}]), __FILE__, __LINE__, "{message}", "{message}")'


def get_c_api(kernel_name: str, args: List[cpp_parse.CPPArg], has_return_value) -> str:
    template_with_return = '''
int {}__c_api(MATXScriptAny* args, int num_args, MATXScriptAny* out_ret_value, void* resource_handle = nullptr)
{{
  TArgs args_t(args, num_args);

  if (num_args > 0 && args[num_args - 1].code == TypeIndex::kRuntimeKwargs) {{
    string_view arg_names[{}] {{{}}};
    KwargsUnpackHelper helper("{}", arg_names, {}, nullptr, 0);
    RTView pos_args[{}];
    helper.unpack(pos_args, args, num_args);  // /Users/bytedance/Developer/open_source_library/matxscript/examples/simple_function.py:5

    auto ret = {}({},
                {}resource_handle);
    RTValue(std::move(ret)).MoveToCHost(out_ret_value);
  }} else {{
    switch(num_args) {{
      case {}: {{
        auto ret = {}({},
                    {}resource_handle);  // /Users/bytedance/Developer/open_source_library/matxscript/examples/simple_function.py:5
        RTValue(std::move(ret)).MoveToCHost(out_ret_value);
      }} break;
      default: {{THROW_PY_TypeError("TODO");}} break;  // /Users/bytedance/Developer/open_source_library/matxscript/examples/simple_function.py:5
    }}
  }}

  return 0;
}}
'''
    assert has_return_value
    template = template_with_return

    num_args = len(args)
    arg_names_concat_str = ', '.join([f'"{arg.name}"' for arg in args])
    args_dtype = [arg.type.name for arg in args]

    pos_arg_cast_lst = []
    args_t_cast_lst = []
    for arg_index in range(num_args):
        pos_arg_cast_lst.append(generate_ndarray_arg_cast('pos_args', arg_index))
        args_t_cast_lst.append(generate_ndarray_arg_cast('args_t', arg_index))

    kernel_name_indentation = len(kernel_name) * ' '
    if has_return_value:
        return_name_indentation = ' ' * 11
    else:
        return_name_indentation = ''
    pos_arg_cast_indentation = '\n     ' + kernel_name_indentation + return_name_indentation
    args_t_cast_indentation = '\n         ' + kernel_name_indentation + return_name_indentation
    pos_arg_cast = (',' + pos_arg_cast_indentation).join(pos_arg_cast_lst)
    args_t_cast = (',' + args_t_cast_indentation).join(args_t_cast_lst)

    return template.format(
        kernel_name,
        num_args,
        arg_names_concat_str,
        kernel_name,
        num_args,
        num_args,
        kernel_name,
        pos_arg_cast,
        kernel_name_indentation,
        num_args,
        kernel_name,
        args_t_cast,
        kernel_name_indentation)


def get_registration_str(kernel_name):
    # TODO: currently, only 1 function is here.
    template = '''
extern "C" {{

MATX_DLL MATXScriptBackendPackedCFunc __matxscript_func_array__[] = {{
    (MATXScriptBackendPackedCFunc){}__c_api,
}};
MATX_DLL MATXScriptFuncRegistry __matxscript_func_registry__ = {{
    "1\\000{}\\000",    __matxscript_func_array__,
}};

}} // extern C

extern "C" {{

MATX_DLL const char* __matxscript_closures_names__ = "1\\000{}\\000";

}} // extern C

    '''
    return template.format(kernel_name, kernel_name, kernel_name)


def get_c_api_declare(kernel_name):
    return f'int {kernel_name}__c_api(MATXScriptAny*, int, MATXScriptAny*, void*);'


def extract_cpp_code(code: str):
    return code.split("'''")[1][1:-1]


def split_include_kernel(code):
    first_newline_idx = code.find('\n')
    include_code_str = code[:first_newline_idx]
    kernel_code_str = code[first_newline_idx + 1:]
    return include_code_str, kernel_code_str


def split_declaration_body(kernel_code_str):
    first_open_bracket = kernel_code_str.find('{')
    kernel_declaration_str = kernel_code_str[:first_open_bracket]
    kernel_body_str = kernel_code_str[first_open_bracket:]
    return kernel_declaration_str, kernel_body_str


def generate_kernel_wrapper_declaration(kernel_name, example_inputs):
    return_type = cpp_parse.CPPType(name='Tuple', is_pointer=False)
    args = []
    for i in range(len(example_inputs)):
        arg = cpp_parse.CPPArg(
            name=f'in_ptr{i}',
            type=cpp_parse.CPPType(
                name='NDArray',
                is_pointer=False),
            is_const=False,
            is_restricted=False)
        args.append(arg)
    kernel_wrapper_declaration = cpp_parse.CPPDeclaration(func_name=kernel_name,
                                                          return_type=return_type,
                                                          args=args,
                                                          is_extern_c=False)
    return kernel_wrapper_declaration


def generate_ndarray_allocate_statement(
        output_name: str,
        dtype: str,
        device: str,
        shape: List[int]):
    assert dtype in ['int32', 'int64', 'float32', 'float64']
    assert device == 'cpu'
    assert isinstance(shape, List)
    for shape_int in shape:
        assert isinstance(shape_int, int)

    shape = [str(shape_int) for shape_int in shape]
    shape_str = ', '.join(shape)

    return f'NDArray {output_name} = createNDArray("{dtype}", "{device}", {{{shape_str}}});'


def generate_ndarray_cast(var_name, dtype):
    return f'({dtype}*){var_name}.Data<{dtype}>()'


def generate_kernel_wrapper_return(fake_output):
    output_str = [f'out_ptr{i}' for i in range(len(fake_output))]
    output_str = ','.join(output_str)
    return f'return Kernel_Tuple::make(std::initializer_list<Tuple::value_type>{{{output_str}}});'


TORCH_DTYPE_TO_NDARRAY_DTYPE = {
    torch.float32: 'float32',
    torch.float64: 'float64',
    torch.int32: 'int32',
    torch.int64: 'int64'
}


def generate_kernel_wrapper_body(kernel_declaration: cpp_parse.CPPDeclaration,
                                 fake_output: List[torch.Tensor]):
    # step 0: obtain output args from kernel_declaration

    # step 1: allocate output NDArray
    ndarray_allocate_statements = []
    for i, output in enumerate(fake_output):
        assert output.dtype in TORCH_DTYPE_TO_NDARRAY_DTYPE
        dtype = TORCH_DTYPE_TO_NDARRAY_DTYPE[output.dtype]

        ndarray_allocate_statement = generate_ndarray_allocate_statement(output_name=f'out_ptr{i}',
                                                                         dtype=dtype,
                                                                         device=str(output.device),
                                                                         shape=list(output.shape))
        ndarray_allocate_statements.append(ndarray_allocate_statement)

    ndarray_allocate_statements = '\n'.join(ndarray_allocate_statements) + '\n\n'

    # step 2: invoke kernel
    kernel_invoke_param = []
    for arg in kernel_declaration.args:
        kernel_invoke_param.append(generate_ndarray_cast(var_name=arg.name, dtype=arg.type.name))

    num_space = 10
    delimiter = ',\n' + ' ' * 10
    kernel_invoke_param_str = delimiter.join(kernel_invoke_param)
    kernel_invoke_str = kernel_declaration.func_name + '(' + '\n' + ' ' * num_space + \
        kernel_invoke_param_str + '\n' + ');' + '\n'

    # step 3: return output as a Tuple
    return_str = generate_kernel_wrapper_return(fake_output)

    # step 4: add bracket
    final_result = '\n{\n' + ndarray_allocate_statements + kernel_invoke_str + return_str + '\n}'

    return final_result


def matx_cpp_code_format(code: str, kernel_name: str,
                         example_inputs: List[torch.Tensor],
                         fake_output: List[torch.Tensor]) -> str:
    code = extract_cpp_code(code)
    # split include and kernel code

    include_code_str, kernel_code_str = split_include_kernel(code)
    # add matx include
    include_code_str += MATX_INCLUDE

    # extract kernel declaration
    kernel_declaration_str, kernel_body_str = split_declaration_body(kernel_code_str)

    kernel_declaration = cpp_parse.parse_cpp_declaration(kernel_declaration_str)
    kernel_return_type = kernel_declaration.return_type.name
    assert kernel_return_type == 'void', f'The kernel return type must be void, Got {kernel_return_type}'

    # TODO: currently, we simply add magic number to avoid conflict
    kernel_declaration.func_name += MAGIC_NUMBER
    kernel_code_str = str(kernel_declaration) + kernel_body_str

    # here, we keep the original kernel and add a wrapper
    kernel_wrapper_declaration = generate_kernel_wrapper_declaration(kernel_name, example_inputs)
    kernel_wrapper_body = generate_kernel_wrapper_body(kernel_declaration, fake_output)

    kernel_wrapper_declaration_without_default = copy.deepcopy(kernel_wrapper_declaration)
    kernel_wrapper_declaration_without_default.append_arg(SESSION_HANLDER)
    kernel_wrapper_declaration_with_default = copy.deepcopy(kernel_wrapper_declaration)
    kernel_wrapper_declaration_with_default.append_arg(SESSION_HANLDER_WITH_DEAFULT)

    # create all the declarations strings
    CREATE_NDARRAY_DECLARATION = split_declaration_body(CREATE_NDARRAY_IMPLEMENTATION)[0] + ';'

    function_declaration = [
        CREATE_NDARRAY_DECLARATION,
        str(kernel_wrapper_declaration_with_default) + ';',
        str(kernel_declaration) + ';',
        get_c_api_declare(
            kernel_wrapper_declaration.func_name)]

    function_declaration_str = '\n\n'.join(function_declaration) + '\n'

    # create all the kernel implementation strings including
    # 1. create ndarray. 2. kernel wrapper, 3. kernel, 4. kernel-c-api
    kernel_wrapper = str(kernel_wrapper_declaration_without_default) + kernel_wrapper_body
    kernel_c_api_impl_str = get_c_api(
        kernel_name=kernel_wrapper_declaration.func_name,
        args=kernel_wrapper_declaration.args,
        has_return_value=kernel_wrapper_declaration.return_type.name != 'void')

    implementations = [
        CREATE_NDARRAY_IMPLEMENTATION,
        kernel_wrapper,
        kernel_code_str,
        kernel_c_api_impl_str]
    implementations_str = '\n\n'.join(implementations) + '\n'

    # add namespace
    kernel_code_str = [
        'namespace {',
        function_declaration_str,
        implementations_str,
        '} // namespace']
    kernel_code_str = '\n\n'.join(kernel_code_str)

    # registration str
    registration_code_str = get_registration_str(kernel_name=kernel_wrapper_declaration.func_name)

    # final code
    final_code = [include_code_str, kernel_code_str, registration_code_str]

    final_code = '\n\n'.join(final_code)

    return final_code
